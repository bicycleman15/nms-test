{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMS function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_pytorch(P : torch.tensor ,thresh_iou : float):\n",
    "    \"\"\"Apply non-maximum suppression to avoid detecting too many\n",
    "    overlapping bounding boxes for a given object.\n",
    "    Args:\n",
    "        boxes: (tensor) The location preds for the image \n",
    "            along with the class predscores, Shape: [num_boxes,5].\n",
    "        thresh_iou: (float) The overlap thresh for suppressing unnecessary boxes.\n",
    "    Returns:\n",
    "        A list of filtered boxes, Shape: [ , 5]\n",
    "    \"\"\"\n",
    "\n",
    "    # we extract coordinates for every \n",
    "    # prediction box present in P\n",
    "    x1 = P[:, 0]\n",
    "    y1 = P[:, 1]\n",
    "    x2 = P[:, 2]\n",
    "    y2 = P[:, 3]\n",
    "\n",
    "    # we extract the confidence scores as well\n",
    "    scores = P[:, 4]\n",
    "\n",
    "    # calculate area of every block in P\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    \n",
    "    # sort the prediction boxes in P\n",
    "    # according to their confidence scores\n",
    "    order = scores.argsort()\n",
    "\n",
    "    # initialise an empty list for \n",
    "    # filtered prediction boxes\n",
    "    keep = []\n",
    "    \n",
    "\n",
    "    while len(order) > 0:\n",
    "        \n",
    "        # extract the index of the \n",
    "        # prediction with highest score\n",
    "        # we call this prediction S\n",
    "        idx = order[-1]\n",
    "\n",
    "        # push S in filtered predictions list\n",
    "        keep.append(P[idx])\n",
    "\n",
    "        # remove S from P\n",
    "        order = order[:-1]\n",
    "\n",
    "        # sanity check\n",
    "        if len(order) == 0:\n",
    "            break\n",
    "        \n",
    "        # select coordinates of BBoxes according to \n",
    "        # the indices in order\n",
    "        xx1 = torch.index_select(x1,dim = 0, index = order)\n",
    "        xx2 = torch.index_select(x2,dim = 0, index = order)\n",
    "        yy1 = torch.index_select(y1,dim = 0, index = order)\n",
    "        yy2 = torch.index_select(y2,dim = 0, index = order)\n",
    "\n",
    "        # find the coordinates of the intersection boxes\n",
    "        xx1 = torch.max(xx1, x1[idx])\n",
    "        yy1 = torch.max(yy1, y1[idx])\n",
    "        xx2 = torch.min(xx2, x2[idx])\n",
    "        yy2 = torch.min(yy2, y2[idx])\n",
    "\n",
    "        # find height and width of the intersection boxes\n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "        \n",
    "        # take max with 0.0 to avoid negative w and h\n",
    "        # due to non-overlapping boxes\n",
    "        w = torch.clamp(w, min=0.0)\n",
    "        h = torch.clamp(h, min=0.0)\n",
    "\n",
    "        # find the intersection area\n",
    "        inter = w*h\n",
    "\n",
    "        # find the areas of BBoxes according the indices in order\n",
    "        rem_areas = torch.index_select(areas, dim = 0, index = order) \n",
    "\n",
    "        # find the union of every prediction T in P\n",
    "        # with the prediction S\n",
    "        # Note that areas[idx] represents area of S\n",
    "        union = (rem_areas - inter) + areas[idx]\n",
    "        \n",
    "        # find the IoU of every prediction in P with S\n",
    "        IoU = inter / union\n",
    "\n",
    "        # keep the boxes with IoU less than thresh_iou\n",
    "        mask = IoU < thresh_iou\n",
    "        order = order[mask]\n",
    "    \n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_image(img_name,raw_img,boxes):\n",
    "    \"\"\"Utility function to save an image with\n",
    "       prediction boxes\n",
    "    \"\"\"\n",
    "    \n",
    "    # iterate over every BBox\n",
    "    for b in boxes:\n",
    "        text = \"{:.4f}\".format(b[4])\n",
    "        b = list(map(int, b))\n",
    "        cv2.rectangle(raw_img, (b[0], b[1]), (b[2], b[3]), (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imwrite(img_name, raw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_file(file_name = 'labels.txt'):\n",
    "    \"\"\"Utility function to read the file\n",
    "       containing prediction boxes and return\n",
    "       a tensor\n",
    "    \"\"\"\n",
    "    # read the labels file\n",
    "    file = open('labels.txt','r')\n",
    "    boxes = []\n",
    "    for line in file:\n",
    "        # remove new line char\n",
    "        line = line[:-2]\n",
    "        line = line.split(' ')\n",
    "        box = [float(num) for num in line]\n",
    "        boxes.append(box)\n",
    "    \n",
    "    file.close()\n",
    "    boxes = torch.tensor(boxes) \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_image(image_path = 'sample.jpg'):\n",
    "    \"\"\"Utility function to read an image and return\n",
    "       in raw form.\n",
    "    \"\"\"\n",
    "    img_raw = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    img_raw=cv2.resize(img_raw,(633,633))\n",
    "    return img_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the `labels.txt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = _read_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the `boxes.shape`. We see there are total of 309 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([309, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at any random prediction BBox, we see that it is of the form `(x1,y1,x2,y2,c)` where `(x1,y1)` is the bottom left corner of the BBox and `(x2,y2)` is the upper right corner of the BBox and `c` is the class prediction score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([335.0970,  71.8290, 393.5530, 196.8940,   0.7440])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply NMS over the prediction BBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_boxes = nms_pytorch(boxes,thresh_iou=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at `filtered_boxes`, we see that out of `309` predictions only `9` remained after applying NMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([321.0950, 325.1020, 393.6710, 455.9300,   0.9940]),\n",
       " tensor([ 75.7170, 155.0710, 143.9270, 274.0190,   0.9930]),\n",
       " tensor([ 60.7890, 357.5100, 130.7250, 484.8780,   0.9880]),\n",
       " tensor([493.2310, 338.0570, 561.1060, 474.9590,   0.9810]),\n",
       " tensor([405.5730,  97.7150, 471.9640, 229.7850,   0.9800]),\n",
       " tensor([199.3570, 347.2870, 263.9680, 480.0680,   0.9760]),\n",
       " tensor([333.1320,  70.1250, 391.6350, 196.2080,   0.9680]),\n",
       " tensor([262.9670, 167.8600, 321.5730, 280.3220,   0.9670]),\n",
       " tensor([170.7110, 104.0130, 232.0630, 230.4070,   0.9600])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the corresponding image and plot the prediction boxes before and after we applied NMS to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = _load_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_image('before_nms.jpg',img.copy(),boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_image('after_nms.jpg',img.copy(), filtered_boxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
